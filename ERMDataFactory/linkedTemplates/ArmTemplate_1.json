{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory Name",
			"defaultValue": "ERMDataFactory"
		},
		"triggerWhenFileInBlobStorage_properties_typeProperties_scope": {
			"type": "string",
			"defaultValue": "/subscriptions/7929cc89-eab0-4bb8-bec5-a5c6f38494fb/resourceGroups/ERM-ETL/providers/Microsoft.Storage/storageAccounts/ermsourceblob"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Trasformation1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText1",
								"type": "DatasetReference"
							},
							"name": "source1",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputTable",
								"type": "DatasetReference"
							},
							"name": "TransformedDataToSQL"
						}
					],
					"transformations": [
						{
							"name": "Select1"
						},
						{
							"name": "Aggregate1"
						}
					],
					"script": "\n\nsource(output(\n\t\t{MeterPoint Code} as string,\n\t\t{Serial Number} as string,\n\t\t{Plant Code} as string,\n\t\t{Date/Time} as date,\n\t\t{Data Type} as string,\n\t\t{Data Value} as double,\n\t\tUnits as string,\n\t\tStatus as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpurgeFiles: true,\n\tdateFormats: ['dd-MM-yyyy'],\n\ttimestampFormats: ['MM/dd/yyyy']) ~> source1\nsource1 select(mapColumn(\n\t\t{MeterPoint Code},\n\t\t{Date/Time},\n\t\t{Data Type},\n\t\t{Data Value}\n\t)) ~> Select1\nSelect1 aggregate(groupBy({Date/Time},\n\t\t{MeterPoint Code},\n\t\t{Data Type}),\n\t{Average Value} = avg({Data Value}),\n\t\t{Minimum Value} = min({Data Value}),\n\t\t{Maximum Value} = max({Data Value}),\n\t\t{Median Value} = mean({Data Value})) ~> Aggregate1\nAggregate1 sink(input(\n\t\tId as integer,\n\t\tDateTime as date,\n\t\t{Meterpoint Code} as string,\n\t\t{Data Type} as string,\n\t\t{Average Value} as double,\n\t\t{Minimum Value} as double,\n\t\t{Maximum Value} as double,\n\t\t{Median Value} as double\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'table',\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tmapColumn(\n\t\tDateTime = {Date/Time},\n\t\t{Meterpoint Code} = {MeterPoint Code},\n\t\t{Data Type},\n\t\t{Average Value},\n\t\t{Minimum Value},\n\t\t{Maximum Value},\n\t\t{Median Value}\n\t)) ~> TransformedDataToSQL"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow3')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText2",
								"type": "DatasetReference"
							},
							"name": "source1",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimittedTestSchemaDrift",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Aggregate1"
						},
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Select1"
						}
					],
					"script": "\n\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinferDriftedColumnTypes: true,\n\tdateFormats: ['dd/MM/yyyy']) ~> source1\nSelect1 aggregate(groupBy({Serial%} = Serial,\n\t\tMeter,\n\t\tDataType),\n\teach(match(name=='Energy'), concat('', 'Data Value') = round(avg($$)))) ~> Aggregate1\nsource1 derive(each(match(name=='Energy'), $$+'val' = toDouble($$)),\n\t\tSerial = byName('Serial'),\n\t\tMeter = byPosition(1),\n\t\tDataType = case(startsWith(toString(byPosition(7)), 'D'), toString(byName('Data Type')),toString(byName('DataType'))),\n\t\teach(match(name=='MeterCode'), $$ + 'Test' = toString($$)),\n\t\teach(match(name=='DataType'), $$ + 'val' = toString($$))) ~> DerivedColumn1\nDerivedColumn1 select(mapColumn(\n\t\tSerial,\n\t\tMeter,\n\t\tDataType\n\t)) ~> Select1\nAggregate1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tmapColumn(\n\t\tSerial = {Serial%},\n\t\teach(match(name=='Data Value'))\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DataflowCopy1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Run dataflow with Explicit copy to ingest copy source",
				"activities": [
					{
						"name": "Trasformation",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Trasformation1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {
										"test": "*.csv"
									},
									"TransformedDataToSQL": {}
								}
							},
							"staging": {}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/Trasformation1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ExecuteDataFlow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow3",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow3')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/triggerWhenFileInBlobStorage')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "pipeline1",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "BlobEventsTrigger",
				"typeProperties": {
					"blobPathBeginsWith": "/ermblob/blobs/",
					"blobPathEndsWith": ".csv",
					"scope": "[parameters('triggerWhenFileInBlobStorage_properties_typeProperties_scope')]",
					"events": [
						"Microsoft.Storage.BlobCreated"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/pipelines/pipeline1')]"
			]
		}
	]
}